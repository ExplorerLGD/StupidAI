import gym, os
from itertools import count
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.distributions import Categorical


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
env = gym.make("CartPole-v0").unwrapped

state_size = env.observation_space.shape[0]
action_size = env.action_space.n

class Actor(nn.Module):
    def __init__(self,state_size,action_size):
        super(Actor,self).__init__()
        self.state_size=state_size
        self.action_size=action_size
        self.l1=nn.Linear(self.state_size,128)
        self.l2=nn.Linear(128,256)
        self.l3=nn.Linear(256,self.action_size)

    def forward(self,state):
        x=F.relu(self.l1(state))
        x=F.relu(self.l2(x))
        x=self.l3(x)
        #x=Categorical(F.softmax(x,dim=-1))
        return x

def test(actor):
    state=env.reset()
    for i in count():
        state=torch.FloatTensor(state).to(device)
        action=actor(state).max(0)[1]
        next_state,reward,done,_=env.step(action.item())
        if done:
            state=env.reset()
        else:
            state=next_state
        env.render()

if __name__ == '__main__':
    actor = Actor(state_size, action_size).to(device)

    if os.path.exists('Model/ActorCritic/actor.pkl'):
        actor.load_state_dict(torch.load("Model/ActorCritic/actor.pkl"))
    else:
        print('model not find')
    actor.eval()
    test(actor)
