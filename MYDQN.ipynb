{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MYDQN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ExplorerLGD/StupidAI/blob/master/MYDQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwu6mttxsNkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# if gpu is to be used\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIzZeWR_0zIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self,):\n",
        "    super(Net,self).__init__()\n",
        "    self.fc1=nn.Linear(1,50)\n",
        "    self.fc1.weight.data.normal_(0,0.1)\n",
        "    self.out=nn.Linear(50,1)\n",
        "    self.fc1.weight.data.normal_(0,0.1)\n",
        "  def forward(self,x):\n",
        "    x=self.fc1(x)\n",
        "    x=F.relu(x)\n",
        "    x=self.out(x)\n",
        "    actions_value=torch.floor(torch.tanh(x) * 10.0)\n",
        "    return actions_value\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VchtZrZO9PCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Saves a transition.\"\"\"\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = Transition(*args)\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnqyseY09PTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 200\n",
        "TARGET_UPDATE = 10\n",
        "\n",
        "policy_net = Net().to(device)\n",
        "target_net = Net().to(device)\n",
        "\n",
        "memory=ReplayMemory(10000)\n",
        "steps_done=0\n",
        "\n",
        "def select_action(state):\n",
        "  global steps_done\n",
        "  sample=random.random()\n",
        "  eps_threshold=EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
        "  if sample>eps_threshold:\n",
        "    with torch.no_grad():\n",
        "      return policy_net(state).view(1, 1)\n",
        "  else:\n",
        "    return torch.tensor([[random.randrange(-10,10)]], device=device, dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aY9ZfmnTIEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimize_model():\n",
        "  if len(memory)<BATCH_SIZE:\n",
        "    return \n",
        "  transitions=memory.sample(BATCH_SIZE)\n",
        "  batch=Transition(*zip(*transitions))\n",
        "  \n",
        "  print(batch.next_state[0].size())\n",
        "  print(batch.next_state)\n",
        "\n",
        "  non_final_mask=torch.tensor(tuple(map(lambda s: s is not None,batch.next_state)),device=device,dtype=torch.uint8)\n",
        "  non_final_next_states=torch.cat([s for s in batch.next_state if s is not None])\n",
        "  \n",
        "  state_batch=torch.cat(batch.state)\n",
        "  action_batch=torch.cat(batch.action)\n",
        "  reward_batch=torch.cat(batch.reward)\n",
        "  \n",
        "  state_action_values=policy_net(state_batch).gather(1,action_batch)\n",
        "  next_state_values=torch.zeros(BATCH_SIZE,device=device)\n",
        "  \n",
        "  next_state_values[non_final_mask]=target_net(non_final_next_states).max(1)[0].detach()\n",
        "  expected_state_action_values=(next_state_values*GAMMA)+reward_batch\n",
        "  \n",
        "  loss=F.smooth_l1_loss(state_action_values,expected_state_action_values.unsqueeze(1))\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  for param in policy_net.parameters():\n",
        "    param.grad.data.clamp_(-1,1)\n",
        "  optimizer.step()\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShGxyB3kPd0v",
        "colab_type": "code",
        "outputId": "58338863-f7b7-4fb9-d0a5-6a4e1d39cbf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2731
        }
      },
      "source": [
        "num_episodes=50\n",
        "for i_episode in range(num_episodes):\n",
        "  state=torch.tensor([[random.randrange(10)]], device=device, dtype=torch.float)\n",
        "  for t in count():\n",
        "    action=select_action(state)\n",
        "    print(action)\n",
        "    #_,reward,done,_=env.step(action.item())\n",
        "    #write reward system,set final state is 10\n",
        "    final_state=torch.tensor([[10]], device=device, dtype=torch.float)\n",
        "    reward=-abs(final_state-(state+action))\n",
        "    #if reward=0,that means get final state\n",
        "    \n",
        "    #observe new state\n",
        "    if reward!=0:\n",
        "      next_state=state+action\n",
        "    else:\n",
        "      next_state=None\n",
        "      print(\"Game Over\")\n",
        "      \n",
        "    memory.push(state,action,next_state,reward)\n",
        "    state=next_state\n",
        "    \n",
        "    optimize_model()\n",
        "    if reward==0:\n",
        "      break\n",
        "  if i_episode % TARGET_UPDATE==0:\n",
        "    target_net.load_state_dict(policy_net.state_dict())\n"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-4.]], device='cuda:0')\n",
            "tensor([[-8.]], device='cuda:0')\n",
            "tensor([[7.]], device='cuda:0')\n",
            "tensor([[7.]], device='cuda:0')\n",
            "tensor([[9.]], device='cuda:0')\n",
            "tensor([[7.]], device='cuda:0')\n",
            "tensor([[3.]], device='cuda:0')\n",
            "tensor([[-10.]], device='cuda:0')\n",
            "tensor([[-6.]], device='cuda:0')\n",
            "tensor([[2.]], device='cuda:0')\n",
            "tensor([[-10.]], device='cuda:0')\n",
            "tensor([[0.]], device='cuda:0')\n",
            "tensor([[0.]], device='cuda:0')\n",
            "tensor([[0.]], device='cuda:0')\n",
            "tensor([[-4.]], device='cuda:0')\n",
            "tensor([[-1.]], device='cuda:0')\n",
            "tensor([[2.]], device='cuda:0')\n",
            "tensor([[7.]], device='cuda:0')\n",
            "tensor([[4.]], device='cuda:0')\n",
            "tensor([[-8.]], device='cuda:0')\n",
            "tensor([[7.]], device='cuda:0')\n",
            "tensor([[0.]], device='cuda:0')\n",
            "tensor([[-3.]], device='cuda:0')\n",
            "tensor([[-7.]], device='cuda:0')\n",
            "tensor([[5.]], device='cuda:0')\n",
            "tensor([[3.]], device='cuda:0')\n",
            "tensor([[8.]], device='cuda:0')\n",
            "tensor([[2.]], device='cuda:0')\n",
            "tensor([[1.]], device='cuda:0')\n",
            "tensor([[7.]], device='cuda:0')\n",
            "tensor([[-6.]], device='cuda:0')\n",
            "tensor([[-4.]], device='cuda:0')\n",
            "tensor([[7.]], device='cuda:0')\n",
            "tensor([[1.]], device='cuda:0')\n",
            "tensor([[-9.]], device='cuda:0')\n",
            "tensor([[1.]], device='cuda:0')\n",
            "tensor([[2.]], device='cuda:0')\n",
            "tensor([[-8.]], device='cuda:0')\n",
            "tensor([[-10.]], device='cuda:0')\n",
            "tensor([[0.]], device='cuda:0')\n",
            "tensor([[-7.]], device='cuda:0')\n",
            "tensor([[4.]], device='cuda:0')\n",
            "tensor([[-9.]], device='cuda:0')\n",
            "tensor([[-4.]], device='cuda:0')\n",
            "tensor([[-4.]], device='cuda:0')\n",
            "tensor([[-6.]], device='cuda:0')\n",
            "tensor([[4.]], device='cuda:0')\n",
            "tensor([[7.]], device='cuda:0')\n",
            "tensor([[8.]], device='cuda:0')\n",
            "tensor([[5.]], device='cuda:0')\n",
            "tensor([[1.]], device='cuda:0')\n",
            "tensor([[1.]], device='cuda:0')\n",
            "tensor([[2.]], device='cuda:0')\n",
            "tensor([[4.]], device='cuda:0')\n",
            "tensor([[-9.]], device='cuda:0')\n",
            "tensor([[4.]], device='cuda:0')\n",
            "tensor([[2.]], device='cuda:0')\n",
            "tensor([[4.]], device='cuda:0')\n",
            "tensor([[-1.]], device='cuda:0')\n",
            "tensor([[6.]], device='cuda:0')\n",
            "tensor([[8.]], device='cuda:0')\n",
            "tensor([[8.]], device='cuda:0')\n",
            "tensor([[6.]], device='cuda:0')\n",
            "tensor([[-9.]], device='cuda:0')\n",
            "tensor([[7.]], device='cuda:0')\n",
            "tensor([[5.]], device='cuda:0')\n",
            "tensor([[8.]], device='cuda:0')\n",
            "tensor([[-1.]], device='cuda:0')\n",
            "tensor([[-3.]], device='cuda:0')\n",
            "tensor([[-9.]], device='cuda:0')\n",
            "tensor([[1.]], device='cuda:0')\n",
            "tensor([[-4.]], device='cuda:0')\n",
            "tensor([[4.]], device='cuda:0')\n",
            "tensor([[0.]], device='cuda:0')\n",
            "tensor([[-3.]], device='cuda:0')\n",
            "tensor([[-10.]], device='cuda:0')\n",
            "tensor([[8.]], device='cuda:0')\n",
            "tensor([[7.]], device='cuda:0')\n",
            "tensor([[-7.]], device='cuda:0')\n",
            "tensor([[-7.]], device='cuda:0')\n",
            "tensor([[4.]], device='cuda:0')\n",
            "tensor([[4.]], device='cuda:0')\n",
            "tensor([[-3.]], device='cuda:0')\n",
            "tensor([[1.]], device='cuda:0')\n",
            "tensor([[-10.]], device='cuda:0')\n",
            "tensor([[6.]], device='cuda:0')\n",
            "tensor([[6.]], device='cuda:0')\n",
            "tensor([[-4.]], device='cuda:0')\n",
            "tensor([[4.]], device='cuda:0')\n",
            "tensor([[4.]], device='cuda:0')\n",
            "tensor([[4.]], device='cuda:0')\n",
            "tensor([[5.]], device='cuda:0')\n",
            "tensor([[7.]], device='cuda:0')\n",
            "tensor([[-7.]], device='cuda:0')\n",
            "tensor([[-8.]], device='cuda:0')\n",
            "tensor([[0.]], device='cuda:0')\n",
            "tensor([[-1.]], device='cuda:0')\n",
            "tensor([[-4.]], device='cuda:0')\n",
            "tensor([[-10.]], device='cuda:0')\n",
            "tensor([[2.]], device='cuda:0')\n",
            "tensor([[3.]], device='cuda:0')\n",
            "tensor([[6.]], device='cuda:0')\n",
            "tensor([[6.]], device='cuda:0')\n",
            "tensor([[3.]], device='cuda:0')\n",
            "tensor([[-3.]], device='cuda:0')\n",
            "tensor([[-6.]], device='cuda:0')\n",
            "tensor([[4.]], device='cuda:0')\n",
            "tensor([[-1.]], device='cuda:0')\n",
            "tensor([[-8.]], device='cuda:0')\n",
            "tensor([[4.]], device='cuda:0')\n",
            "tensor([[0.]], device='cuda:0')\n",
            "tensor([[-5.]], device='cuda:0')\n",
            "tensor([[-1.]], device='cuda:0')\n",
            "tensor([[4.]], device='cuda:0')\n",
            "tensor([[-10.]], device='cuda:0')\n",
            "tensor([[3.]], device='cuda:0')\n",
            "tensor([[-8.]], device='cuda:0')\n",
            "tensor([[8.]], device='cuda:0')\n",
            "tensor([[-2.]], device='cuda:0')\n",
            "tensor([[5.]], device='cuda:0')\n",
            "tensor([[0.]], device='cuda:0')\n",
            "tensor([[0.]], device='cuda:0')\n",
            "tensor([[0.]], device='cuda:0')\n",
            "tensor([[5.]], device='cuda:0')\n",
            "tensor([[6.]], device='cuda:0')\n",
            "tensor([[-4.]], device='cuda:0')\n",
            "tensor([[5.]], device='cuda:0')\n",
            "tensor([[8.]], device='cuda:0')\n",
            "torch.Size([1, 1])\n",
            "(tensor([[19.]], device='cuda:0'), tensor([[41.]], device='cuda:0'), tensor([[6.]], device='cuda:0'), tensor([[30.]], device='cuda:0'), tensor([[29.]], device='cuda:0'), tensor([[25.]], device='cuda:0'), tensor([[21.]], device='cuda:0'), tensor([[32.]], device='cuda:0'), tensor([[28.]], device='cuda:0'), tensor([[38.]], device='cuda:0'), tensor([[45.]], device='cuda:0'), tensor([[16.]], device='cuda:0'), tensor([[32.]], device='cuda:0'), tensor([[16.]], device='cuda:0'), tensor([[35.]], device='cuda:0'), tensor([[23.]], device='cuda:0'), tensor([[17.]], device='cuda:0'), tensor([[33.]], device='cuda:0'), tensor([[-4.]], device='cuda:0'), tensor([[24.]], device='cuda:0'), tensor([[25.]], device='cuda:0'), tensor([[7.]], device='cuda:0'), tensor([[30.]], device='cuda:0'), tensor([[29.]], device='cuda:0'), tensor([[13.]], device='cuda:0'), tensor([[11.]], device='cuda:0'), tensor([[-11.]], device='cuda:0'), tensor([[-1.]], device='cuda:0'), tensor([[30.]], device='cuda:0'), tensor([[19.]], device='cuda:0'), tensor([[29.]], device='cuda:0'), tensor([[3.]], device='cuda:0'), tensor([[24.]], device='cuda:0'), tensor([[28.]], device='cuda:0'), tensor([[-1.]], device='cuda:0'), tensor([[9.]], device='cuda:0'), tensor([[-7.]], device='cuda:0'), tensor([[-4.]], device='cuda:0'), tensor([[8.]], device='cuda:0'), tensor([[22.]], device='cuda:0'), tensor([[3.]], device='cuda:0'), tensor([[-11.]], device='cuda:0'), tensor([[26.]], device='cuda:0'), tensor([[30.]], device='cuda:0'), tensor([[12.]], device='cuda:0'), tensor([[-4.]], device='cuda:0'), tensor([[2.]], device='cuda:0'), tensor([[31.]], device='cuda:0'), tensor([[25.]], device='cuda:0'), tensor([[19.]], device='cuda:0'), tensor([[-6.]], device='cuda:0'), tensor([[29.]], device='cuda:0'), tensor([[20.]], device='cuda:0'), tensor([[13.]], device='cuda:0'), tensor([[15.]], device='cuda:0'), tensor([[6.]], device='cuda:0'), tensor([[-1.]], device='cuda:0'), tensor([[31.]], device='cuda:0'), tensor([[24.]], device='cuda:0'), tensor([[-2.]], device='cuda:0'), tensor([[16.]], device='cuda:0'), tensor([[25.]], device='cuda:0'), tensor([[23.]], device='cuda:0'), tensor([[22.]], device='cuda:0'), tensor([[-5.]], device='cuda:0'), tensor([[20.]], device='cuda:0'), tensor([[26.]], device='cuda:0'), tensor([[26.]], device='cuda:0'), tensor([[26.]], device='cuda:0'), tensor([[21.]], device='cuda:0'), tensor([[23.]], device='cuda:0'), tensor([[40.]], device='cuda:0'), tensor([[12.]], device='cuda:0'), tensor([[37.]], device='cuda:0'), tensor([[17.]], device='cuda:0'), tensor([[-5.]], device='cuda:0'), tensor([[19.]], device='cuda:0'), tensor([[15.]], device='cuda:0'), tensor([[7.]], device='cuda:0'), tensor([[1.]], device='cuda:0'), tensor([[14.]], device='cuda:0'), tensor([[30.]], device='cuda:0'), tensor([[-20.]], device='cuda:0'), tensor([[4.]], device='cuda:0'), tensor([[19.]], device='cuda:0'), tensor([[20.]], device='cuda:0'), tensor([[19.]], device='cuda:0'), tensor([[-4.]], device='cuda:0'), tensor([[13.]], device='cuda:0'), tensor([[14.]], device='cuda:0'), tensor([[16.]], device='cuda:0'), tensor([[16.]], device='cuda:0'), tensor([[-16.]], device='cuda:0'), tensor([[4.]], device='cuda:0'), tensor([[24.]], device='cuda:0'), tensor([[25.]], device='cuda:0'), tensor([[3.]], device='cuda:0'), tensor([[-3.]], device='cuda:0'), tensor([[-2.]], device='cuda:0'), tensor([[20.]], device='cuda:0'), tensor([[2.]], device='cuda:0'), tensor([[13.]], device='cuda:0'), tensor([[39.]], device='cuda:0'), tensor([[25.]], device='cuda:0'), tensor([[25.]], device='cuda:0'), tensor([[29.]], device='cuda:0'), tensor([[12.]], device='cuda:0'), tensor([[21.]], device='cuda:0'), tensor([[33.]], device='cuda:0'), tensor([[38.]], device='cuda:0'), tensor([[-1.]], device='cuda:0'), tensor([[-4.]], device='cuda:0'), tensor([[-1.]], device='cuda:0'), tensor([[-24.]], device='cuda:0'), tensor([[-1.]], device='cuda:0'), tensor([[-6.]], device='cuda:0'), tensor([[14.]], device='cuda:0'), tensor([[-30.]], device='cuda:0'), tensor([[19.]], device='cuda:0'), tensor([[-7.]], device='cuda:0'), tensor([[-3.]], device='cuda:0'), tensor([[29.]], device='cuda:0'), tensor([[8.]], device='cuda:0'), tensor([[21.]], device='cuda:0'), tensor([[6.]], device='cuda:0'), tensor([[-10.]], device='cuda:0'), tensor([[-19.]], device='cuda:0'), tensor([[-26.]], device='cuda:0'))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-172-8808bf5502b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-171-ee1ea27e3e09>\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mreward_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mstate_action_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mnext_state_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #3 'index'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2XkwywnAtEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#以下均为测试代码，羞羞勿看 O(∩_∩)O"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8mqraZrRGkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self,):\n",
        "    super(Net,self).__init__()\n",
        "    self.fc1=nn.Linear(1,50)\n",
        "    self.fc1.weight.data.normal_(0,0.1)\n",
        "    self.out=nn.Linear(50,1)\n",
        "    self.fc1.weight.data.normal_(0,0.1)\n",
        "  def forward(self,x):\n",
        "    x=self.fc1(x)\n",
        "    x=F.relu(x)\n",
        "    actions_value=self.out(x)\n",
        "    return torch.floor(torch.tanh(actions_value) * 10.0)\n",
        "net=Net().to(device)\n",
        "a=net(torch.tensor([[10],[5]], device=device, dtype=torch.float))\n",
        "print(a.max(0)[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6xaALO7V1Pz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=Transition(1,2,3,4)\n",
        "y=Transition(5,6,7,8)\n",
        "test=[x,y]\n",
        "\n",
        "print(tuple(map(lambda s:s is not None,test)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvQctb3tB_uM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=torch.tensor([[2,3]])\n",
        "b=torch.tensor([[4,5]])\n",
        "if a.size() !=torch.size([1,2]):\n",
        "  print(\"false\")\n",
        "print(a.size())\n",
        "print(c)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}